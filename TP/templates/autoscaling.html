<h1>Atelier AutoScaling EC2</h1>
<p>Nous allons utiliser l&#39;<a href="http://aws.amazon.com/fr/autoscaling/">AutoScaling AWS</a> pour mettre en place un webservice de manipulation d&#39;images qui puisse s&#39;adapter à la charge entrante tout en minimisant les coûts de possession. Pour cela, nous allons partir d&#39;une AMI, automatiser intégralement son lancement, puis l&#39;injecter dans la configuration de notre groupe d&#39;autoscaling afin de pouvoir faire varier le nombre de machines derrière un Elastic Load Balancer.</p>
<p><img src="Architecture.png" alt="Autoscaling"></p>
<p>Pour information, nous allons utiliser une AMI Amazon sur laquelle nous allons installer NodeJS, ImageMagick et <a href="https://github.com/dawanda/node-imageable-server">node-imageable-server</a>, pour fournir un webservice basique (qui tournera en root sur le port 80). Il est également nécessaire d&#39;installer les <a href="http://aws.amazon.com/developertools/351">EC2 API tools</a>, les <a href="http://aws.amazon.com/developertools/2536">ELB tools</a>, les <a href="http://aws.amazon.com/developertools/2534">CloudWatch tools</a> et les <a href="http://aws.amazon.com/developertools/2535">AutoScaling tools</a>.</p>
<h2>Automatisation du boot de l&#39;instance</h2>
<p>Afin d&#39;aller à l&#39;essentiel (cette partie du job peut tout à fait être effectuée par un outil d&#39;orchestration comme Puppet), nous utiliserons les user-data de l&#39;instance pour injecter un script shell exécuté en fin de boot. Celui-ci est en charge :</p>
<ul>
<li>de l&#39;installation de NodeJS, git et ImageMagick,</li>
<li>l&#39;optimisation réseau afin de gérer un grand nombre de courtes connexions TCP simultanées,</li>
<li>l&#39;installation et le lancement de node-imageable-server.</li>
</ul>
<p>L&#39;ensemble du script de lancement à passer en user-data est fourni en pièce-jointe de cette page <a href="user-data-imageable">user-data-imageable</a>. A noter qu&#39;il est primordial de minimiser le temps de boot d&#39;une instance afin que notre groupe d&#39;autoscaling soit suffisamment réactif en cas de pic de charge.
Nous allons maintenant pouvoir déclarer les éléments d&#39;infrastructure : ELB et AutoScaling</p>
<h2>Déclaration de l&#39;ELB</h2>
<p>On déclare un ELB nommé upicardie-asdemo sur la zone us-east-1d, qui écoute sur le port 80 et qui répartit les requêtes sur le port 80 des instances :</p>
<pre><code>aws elb create-load-balancer \
  --load-balancer-name upicardie-asdemo \
  --availability-zones us-east-1d \
  --listeners &quot;LoadBalancerPort=80,InstancePort=80,Protocol=http&quot;
{
    &quot;DNSName&quot;: &quot;upicardie-asdemo-764036086.us-east-1.elb.amazonaws.com&quot;
}</code></pre>
<p>On configure ses tests de viabilité d&#39;une instance :</p>
<pre><code class="lang-bash">aws elb configure-health-check \
  --load-balancer-name upicardie-asdemo \
  --health-check Target=&quot;HTTP:80/&quot;,Interval=10,Timeout=5,UnhealthyThreshold=2,HealthyThreshold=2
{
    &quot;HealthCheck&quot;: {
        &quot;HealthyThreshold&quot;: 2,
        &quot;Interval&quot;: 10,
        &quot;Target&quot;: &quot;HTTP:80/&quot;,
        &quot;Timeout&quot;: 5,
        &quot;UnhealthyThreshold&quot;: 2
    }
}</code></pre>
<p>Ces tests sont vitaux afin de s&#39;assurer que l&#39;instance cible ne rentre dans l&#39;ELB que quand  elle est pleinement opérationnelle (à l&#39;issue de son boot via user-data)</p>
<h2>Déclaration des groupes de sécurité</h2>
<p>Les instances d&#39;une groupe d&#39;autoscaling ne dérogent pas aux règles en vigueur sur EC2, elles doivent faire partie d&#39;au moins un groupe de sécurité. Ainsi, nous déclarerons :</p>
<ul>
<li>upicardie-asdemo-common : le groupe commun à toutes les instances. Autorise le ping et le SSH de partout.</li>
<li>upicardie-asdemo-web : le groupe des instances Web. Autorise le HTTP à partir du groupe de sécurité de l&#39;ELB (sg-6563ed0e dans notre cas)</li>
</ul>
<pre><code class="lang-bash">aws ec2 create-security-group \
  --group-name upicardie-asdemo-common \
  --description &quot;Serveurs upicardie-asdemo&quot;
{
    &quot;return&quot;: &quot;true&quot;,
    &quot;GroupId&quot;: &quot;sg-8962ece2&quot;
}</code></pre>
<pre><code class="lang-bash">aws ec2 create-security-group \
    --group-name upicardie-asdemo-web \
    --description &quot;Serveurs Web upicardie-asdemo&quot;
{
    &quot;return&quot;: &quot;true&quot;,
    &quot;GroupId&quot;: &quot;sg-6563ed0e&quot;
}</code></pre>
<pre><code class="lang-bash">aws ec2 authorize-security-group-ingress \
  --group-name upicardie-asdemo-common \
  --protocol icmp
  --port -1
{
    &quot;return&quot;: &quot;true&quot;
}</code></pre>
<pre><code class="lang-bash">aws ec2 authorize-security-group-ingress \
  --group-name upicardie-asdemo-common \
  --protocol tcp \
  --port 22
{
    &quot;return&quot;: &quot;true&quot;
}</code></pre>
<pre><code class="lang-bash">aws ec2 authorize-security-group-ingress \
  --group-name upicardie-asdemo-web \
  --protocol tcp \
  --port 80 \
  --source-group sg-6563ed0e
{
    &quot;IpPermissionsEgress&quot;: [],
    &quot;Description&quot;: &quot;Serveurs Web upicardie-asdemo&quot;,
    &quot;IpPermissions&quot;: [
        {
            &quot;ToPort&quot;: 80,
            &quot;IpProtocol&quot;: &quot;tcp&quot;,
            &quot;IpRanges&quot;: [],
            &quot;UserIdGroupPairs&quot;: [
                {
                    &quot;GroupName&quot;: &quot;upicardie-asdemo-web&quot;,
                    &quot;UserId&quot;: &quot;511122800347&quot;,
                    &quot;GroupId&quot;: &quot;sg-6563ed0e&quot;
                }
            ],
            &quot;FromPort&quot;: 80
        }
    ],
    &quot;GroupName&quot;: &quot;upicardie-asdemo-web&quot;,
    &quot;OwnerId&quot;: &quot;511122800347&quot;,
    &quot;GroupId&quot;: &quot;sg-6563ed0e&quot;
}


@TODO ?
ec2auth upicardie-asdemo-web -P tcp -p 80 -u amazon-elb -o sg-6563ed0e</code></pre>
<h2>Création de la configuration de lancement</h2>
<p>Avant de déclarer le groupe d&#39;autoscaling à proprement parler, nous allons définir tout ce qui est relatif à une instance du groupe, à savoir :</p>
<ul>
<li>son AMI (ami-94cd60fd)</li>
<li>son type m1.small</li>
<li>ses groupes de sécurité (upicardie-asdemo-common et upicardie-asdemo-web)</li>
<li>le fichier user-data qu&#39;on a préparé (user-data-imageable, stocké dans le répertoire courant de la machine à partir de laquelle on tape les commandes d&#39;autoscaling)</li>
<li>la clé pour l&#39;accès SSH (MyKeyPair générée normalement plus tôt)</li>
</ul>
<pre><code class="lang-bash">aws autoscaling create-launch-configuration \
  --launch-configuration-name upicardie-asdemo-lc \
  --image-id ami-94cd60fd \
  --instance-type t1.micro \
  --security-groups &#39;[&quot;upicardie-asdemo-common&quot;,&quot;upicardie-asdemo-web&quot;]&#39; \
  --user-data user-data-imageable \
  --key-name MyKeyPair
{}</code></pre>
<pre><code class="lang-bash">aws autoscaling describe-launch-configurations
{
    &quot;LaunchConfigurations&quot;: [
        {
            &quot;UserData&quot;: &quot;dXNlci1kYXRhLWltYWdlYWJsZQ==&quot;,
            &quot;EbsOptimized&quot;: false,
            &quot;LaunchConfigurationARN&quot;: &quot;arn:aws:autoscaling:us-east-1:511122800347:launchConfiguration:4c9d7ee0-47cd-407d-bc5d-bef4f7fe8195:launchConfigurationName/upicardie-asdemo-lc&quot;,
            &quot;InstanceMonitoring&quot;: {
                &quot;Enabled&quot;: true
            },
            &quot;ImageId&quot;: &quot;ami-94cd60fd&quot;,
            &quot;CreatedTime&quot;: &quot;2013-08-28T22:13:31.740Z&quot;,
            &quot;BlockDeviceMappings&quot;: [],
            &quot;KeyName&quot;: &quot;MyKeyPair&quot;,
            &quot;SecurityGroups&quot;: [
                &quot;upicardie-asdemo-common&quot;,
                &quot;upicardie-asdemo-web&quot;
            ],
            &quot;LaunchConfigurationName&quot;: &quot;upicardie-asdemo-lc&quot;,
            &quot;KernelId&quot;: null,
            &quot;RamdiskId&quot;: null,
            &quot;InstanceType&quot;: &quot;t1.micro&quot;
        }
    ]
}</code></pre>
<h2>Création du groupe d&#39;autoscaling</h2>
<p>Maintenant que nous avons défini la configuration de lancement, nous pouvons déclarer le groupe d&#39;autoscaling avec les paramètres suivants :</p>
<ul>
<li>la configuration de lancement (upicardie-asdemo-lc)</li>
<li>la ou les zone(s) sur lesquelles l&#39;autoscaling prend effet (us-east-1d, en accord avec la déclaration de l&#39;ELB)</li>
<li>le nombre minimal et maximal d&#39;instances (pour assurer à la fois une certaine disponibilité/QoS et maîtriser les coûts de possession)</li>
<li>le nom de l&#39;ELB dans lequel inscrire/désinscrire les instances</li>
<li>le type de test de viabilité (soit celui d&#39;EC2, garantissant la partie hardware, soit celui de l&#39;ELB assurant la disponibilité applicative)</li>
<li>la période de grâce (= la durée pendant laquelle l&#39;instance n&#39;est pas testée après son lancement. Grosso-modo son temps de boot).</li>
</ul>
<pre><code class="lang-bash">aws autoscaling create-auto-scaling-group \
  --auto-scaling-group-name upicardie-asdemo-asg \
  --launch-configuration-name upicardie-asdemo-lc \
  --availability-zones us-east-1d \
  --min-size 0 --max-size 0 \
  --load-balancer-names upicardie-asdemo \
  --health-check-type EC2 \
  --health-check-grace-period 300</code></pre>
<pre><code class="lang-bash">aws autoscaling describe-auto-scaling-groups
{
    &quot;AutoScalingGroups&quot;: [
        {
            &quot;AutoScalingGroupARN&quot;: &quot;arn:aws:autoscaling:us-east-1:511122800347:autoScalingGroup:eca4e01a-06f0-4373-8ab2-7210c006c450:autoScalingGroupName/upicardie-asdemo-asg&quot;,
            &quot;HealthCheckGracePeriod&quot;: 300,
            &quot;SuspendedProcesses&quot;: [],
            &quot;DesiredCapacity&quot;: 0,
            &quot;Tags&quot;: [],
            &quot;EnabledMetrics&quot;: [],
            &quot;LoadBalancerNames&quot;: [
                &quot;upicardie-asdemo&quot;
            ],
            &quot;AutoScalingGroupName&quot;: &quot;upicardie-asdemo-asg&quot;,
            &quot;DefaultCooldown&quot;: 300,
            &quot;MinSize&quot;: 0,
            &quot;Instances&quot;: [],
            &quot;MaxSize&quot;: 0,
            &quot;VPCZoneIdentifier&quot;: null,
            &quot;TerminationPolicies&quot;: [
                &quot;Default&quot;
            ],
            &quot;LaunchConfigurationName&quot;: &quot;upicardie-asdemo-lc&quot;,
            &quot;CreatedTime&quot;: &quot;2013-08-28T22:19:51.106Z&quot;,
            &quot;AvailabilityZones&quot;: [
                &quot;us-east-1d&quot;
            ],
            &quot;HealthCheckType&quot;: &quot;EC2&quot;
        }
    ]
}</code></pre>
<h2>Triggers de mise à l&#39;échelle</h2>
<p>Il est ensuite nécessaire de définir la politiques de mises à l&#39;échelle de l&#39;architecture, à la hausse comme à la baisse. Chaque élément AWS (ELB, volume, instance...) dispose de métriques CloudWatch sur lesquelles nous allons nous appuyer pour lancer ou éteindre des machines. Les instances d&#39;un groupe d&#39;autoscaling disposent notamment d&#39;une surveillance CloudWatch détaillée (pas de 1 minute à la place des 5 minutes par défaut).
Commençons par définir notre politique d&#39;ajout de machines (upicardie-asdemo-scale-up) : Nous ajoutons 50% de machines en plus. Le paramètre <code>--cooldown</code> permet de définir une durée (en seconde) pendant laquelle la politique de mise à l&#39;échelle ne sera plus appelée. C&#39;est utile pour laisser les instances se lancer et pour voir les premiers bénéfices de l&#39;ajout d&#39;instances.</p>
<pre><code class="lang-bash">aws autoscaling put-scaling-policy \
  --policy-name upicardie-asdemo-scale-up \
  --auto-scaling-group-name upicardie-asdemo-asg \
  --scaling-adjustment 50 \
  --adjustment-type PercentChangeInCapacity \
  --cooldown 300
{
    &quot;PolicyARN&quot;: &quot;arn:aws:autoscaling:us-east-1:511122800347:scalingPolicy:37583020-faf5-4990-a2ec-0aa0ecad9cae:autoScalingGroupName/upicardie-asdemo-asg:policyName/upicardie-asdemo-scale-up&quot;
}</code></pre>
<p>Même chose pour le retrait de machine : on enlève les machines une à une du groupe d&#39;autoscaling. L&#39;idée est ici de croitre beaucoup plus vite qu&#39;on ne décroit pour pouvoir encaisser facilement des pics de charge successifs.</p>
<pre><code class="lang-bash">aws autoscaling put-scaling-policy \
  --policy-name upicardie-asdemo-scale-down \
  --auto-scaling-group-name upicardie-asdemo-asg \
  --scaling-adjustment -1 \
  --adjustment-type ChangeInCapacity \
  --cooldown 300
{
    &quot;PolicyARN&quot;: &quot;arn:aws:autoscaling:us-east-1:511122800347:scalingPolicy:924d37fe-90f1-466c-90e8-196f9e28b36a:autoScalingGroupName/upicardie-asdemo-asg:policyName/upicardie-asdemo-scale-down&quot;
}</code></pre>
<p>L&#39;invocation des commandes ci-dessus renvoie à chaque fois une référence que nous allons pouvoir injecter dans nos déclencheurs... A commencer par la mise à l&#39;échelle à la hausse lorsque :</p>
<ul>
<li>l&#39;utilisation CPU moyenne (<code>--statistic Average --metric-name CPUUtilization</code>)</li>
<li>du groupe d&#39;autoscaling upicardie-asdemo-asg (<code>--namespace &quot;AWS/EC2&quot; --dimensions &quot;Name=AutoScalingGroupName,Value=upicardie-asdemo-asg&quot;</code>)</li>
<li>est supérieure (<code>--comparison-operator GreaterThanThreshold</code>)</li>
<li>à 70% (<code>--threshold 70</code>)</li>
<li>pendant plus de 2 relevés distants de 60 secondes (`--period 60 --evaluation-periods 2)</li>
</ul>
<pre><code class="lang-bash">aws cloudwatch put-metric-alarm \
  --alarm-name upicardie-asdemo-highcpualarm \
  --comparison-operator GreaterThanThreshold \
  --statistic Average \
  --metric-name CPUUtilization \
  --namespace &quot;AWS/EC2&quot; \
  --dimensions &quot;Name=AutoScalingGroupName,Value=upicardie-asdemo-asg&quot; \
  --period 60 \
  --threshold 70 \
  --evaluation-periods 2 \
  --alarm-actions arn:aws:autoscaling:us-east-1:511122800347:scalingPolicy:37583020-faf5-4990-a2ec-0aa0ecad9cae:autoScalingGroupName/upicardie-asdemo-asg:policyName/upicardie-asdemo-scale-up
{}</code></pre>
<p>Pareil avec la mise à l&#39;échelle à la baisse lorsque :</p>
<ul>
<li>l&#39;utilisation CPU moyenne (<code>--statistic Average --metric-name CPUUtilization</code>)</li>
<li>du groupe d&#39;autoscaling upicardie-asdemo-asg (<code>--namespace &quot;AWS/EC2&quot; --dimensions &quot;Name=AutoScalingGroupName,Value=upicardie-asdemo-asg&quot;</code>)</li>
<li>est supérieure (<code>--comparison-operator LessThanThreshold</code>)</li>
<li>à 36% (<code>--threshold 36</code>)</li>
<li>pendant plus de 2 relevés distants de 60 secondes (<code>--period 60 --evaluation-periods 2</code>)</li>
</ul>
<pre><code class="lang-bash">aws cloudwatch put-metric-alarm \
  --alarm-name upicardie-asdemo-lowcpualarm \
  --comparison-operator LessThanThreshold \
  --statistic Average \
  --metric-name CPUUtilization \
  --namespace &quot;AWS/EC2&quot; \
  --dimensions &quot;Name=AutoScalingGroupName,Value=upicardie-asdemo-asg&quot; \
  --period 60 \
  --threshold 36 \
  --evaluation-periods 2 \
  --alarm-actions arn:aws:autoscaling:us-east-1:511122800347:scalingPolicy:924d37fe-90f1-466c-90e8-196f9e28b36a:autoScalingGroupName/upicardie-asdemo-asg:policyName/upicardie-asdemo-scale-down
{}</code></pre>
<p>Nous allons ensuite prendre soin de la QoS de notre service en définissant une mise à l&#39;échelle à la hausse lorsque :</p>
<ul>
<li>la latence moyenne (<code>--statistic Average --metric-name Latency</code>)</li>
<li>du load-balancer upicardie-asdemo (<code>--namespace &quot;AWS/ELB&quot; --dimensions &quot;Name=LoadBalancerName,Value=upicardie-asdemo&quot;</code>)</li>
<li>est supérieure (<code>--comparison-operator LessThanThreshold</code>)</li>
<li>à 3 secondes (<code>--threshold 3</code>)</li>
<li>dès le premier relevé (<code>--period 60 --evaluation-periods 1</code>)</li>
</ul>
<pre><code class="lang-bash">aws cloudwatch put-metric-alarm \
  --alarm-name upicardie-asdemo-highlatencyalarm \
  --comparison-operator GreaterThanThreshold \
  --statistic Average \
  --metric-name Latency \
  --namespace &quot;AWS/ELB&quot; \
  --dimensions &quot;Name=LoadBalancerName,Value=upicardie-asdemo&quot; \
  --period 60 \
  --threshold 3 \
  --evaluation-periods 1 \
  --alarm-actions arn:aws:autoscaling:us-east-1:511122800347:scalingPolicy:37583020-faf5-4990-a2ec-0aa0ecad9cae:autoScalingGroupName/upicardie-asdemo-asg:policyName/upicardie-asdemo-scale-up
{}</code></pre>
<p>Notre autoscaling est dorénavant fonctionnel. Pour lancer le service, il suffit de passer le min/max du nombre d&#39;instances du groupe d&#39;autoscaling de 0/0 à 2/12 par exemple :</p>
<pre><code class="lang-bash">aws autoscaling update-auto-scaling-group \
  --auto-scaling-group-name upicardie-asdemo-asg \
  --min-size 2 \
  --max-size 12
{}</code></pre>
<h2>Mise à l&#39;échelle programmée</h2>
<p>Dans certains cas, il est possible de prévoir la charge sur la plate-forme et de programmer, à une certaine heure et une certaine récurrence la mise à l&#39;échelle de l&#39;autoscaling en jouant sur le min/max par exemple. Les deux régles suivantes vont définir un passage à 3 instances minimum à 22h15 UTC chaque jour (syntaxe cron) :</p>
<pre><code class="lang-bash">aws aws autoscaling put-scheduled-update-group-action \
  --auto-scaling-group-name upicardie-asdemo-asg \
  --scheduled-action-name upicardie-asdemo-preemptive-upscale \
  --min-size 4 \
  --max-size 12 \
  --recurrence &quot;15 22 * * *&quot;
{}</code></pre>
<p>suivi d&#39;un retour à 2 instances minimum à 4h00 UTC chaque jour :</p>
<pre><code class="lang-bash">aws aws autoscaling put-scheduled-update-group-action \
  --auto-scaling-group-name upicardie-asdemo-asg \
  --scheduled-action-name upicardie-asdemo-preemptive-downscale \
  --min-size 2 \
  --max-size 12 \
  --recurrence &quot;0 4 * * *&quot;
{}</code></pre>
<h2>Mise à jour de l&#39;autoscaling</h2>
<p>Les commandes d&#39;autoscaling prévoient la mise à jour du groupe d&#39;autoscaling, mais pas de la configuration de lancement de ce même groupe. Qu&#39;importe, nous pouvons contourner cette limitation en passant une configuration de lancement temporaire. Si nous voulons par exemple changer l&#39;AMI de nos instances de ami-94cd60fd vers ami-42421337 :</p>
<pre><code class="lang-bash">as-create-launch-config upicardie-asdemo-lc-tmp \
  --image-id ami-42421337 \
  --instance-type m1.small \
  --group upicardie-asdemo-common,upicardie-asdemo-web \
  --user-data-file user-data-imageable \
  --key upicardie-us-east1

as-update-auto-scaling-group upicardie-asdemo-asg \
  --launch-configuration upicardie-asdemo-lc-tmp

as-delete-launch-config -f --launch-config upicardie-asdemo-lc

as-create-launch-config upicardie-asdemo-lc \
  --image-id ami-42421337 \
  --instance-type m1.small \
  --group upicardie-asdemo-common,upicardie-asdemo-web \
  --user-data-file user-data-imageable \
  --key upicardie-us-east1

as-update-auto-scaling-group upicardie-asdemo-asg \
  --launch-configuration upicardie-asdemo-lc

as-delete-launch-config -f --launch-config upicardie-asdemo-lc-tmp</code></pre>
<p>Note : cette double déclaration de configurations de lancement peut être évitée si on horodate le nom de la configuration plutôt que de le garder fixe.</p>
<h2>Fight!</h2>
<p>En guise de démonstration, nous allons utiliser une machine Tsung pour faire monter la charge.</p>
<p>Lancer une instance. Puis</p>
<pre><code>apt-get install erlang-nox
apt-get get install gnuplot-nox libtemplate-perl libfile-spec-perl
wget http://tsung.erlang-projects.org/dist/debian/tsung_1.4.2-1_all.deb
dpkg -i tsung_1.4.2-1_all.deb</code></pre>
<h3>Optimisations systèmes:</h3>
<p>Tout d&#39;abord, nous allons modifier le comportement du noyau Linux afin qu&#39;il :</p>
<ul>
<li>soit plus agressif avec les connexions persistantes (nul besoin que de telles connexions s&#39;accumulent inutilement sur notre système),</li>
<li>puisse allouer un maximum de mémoire à la couche réseau, en conformité avec les spécifications matérielles de notre machines.</li>
</ul>
<p>Ainsi, le script suivant va se charger d&#39;inscrire dans un fichier tous les changements nécessaires :</p>
<pre><code>pagesize=$(getconf PAGE_SIZE)
meminbytes=$(free -b | awk &#39;/^Mem:/ { print $2}&#39;)
cat &gt; /etc/sysctl.d/textme.conf &lt;&lt; EOD
kernel.shmmax = $((meminbytes*9/10))
kernel.shmall = $((meminbytes/pagesize))
vm.min_free_kbytes = $((meminbytes/1024/100))
net.ipv4.tcp_max_tw_buckets = $((meminbytes*512/4194304))
net.ipv4.tcp_max_orphans = $((meminbytes/10/65536))
kernel.pid_max = 65536
kernel.msgmax = 65536
kernel.msgmnb = 65536
vm.dirty_background_ratio = 5
vm.dirty_ratio = 15
net.core.netdev_max_backlog = 262144
net.core.somaxconn = 262144
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216
net.ipv4.tcp_rmem = 4096 87380 16777216
net.ipv4.tcp_wmem = 4096 87380 16777216
net.ipv4.tcp_no_metrics_save = 1
net.ipv4.tcp_moderate_rcvbuf = 1
net.ipv4.tcp_fin_timeout = 10
net.ipv4.tcp_orphan_retries = 1
net.ipv4.tcp_max_syn_backlog = 262144
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_tw_reuse = 1
net.ipv4.conf.default.rp_filter = 0
net.ipv4.conf.all.rp_filter = 0
net.ipv4.tcp_dsack = 1
net.ipv4.tcp_fack = 1
net.ipv4.tcp_sack = 1
net.ipv4.tcp_timestamps = 1
net.ipv4.tcp_window_scaling = 1
net.ipv4.tcp_ecn = 0
net.ipv4.inet_peer_gc_mintime = 5
net.ipv4.ip_local_port_range = 1024 65535
net.ipv4.tcp_rfc1337 = 1
net.ipv4.tcp_syncookies = 0
net.ipv4.tcp_keepalive_probes = 2
net.ipv4.tcp_keepalive_intvl = 2
net.ipv4.tcp_keepalive_time = 60
net.ipv4.tcp_synack_retries = 2
net.ipv4.tcp_syn_retries = 2
EOD</code></pre>
<p>On applique les changements :</p>
<pre><code>service procps restart</code></pre>
<h3>Augmentation des limites des utilisateurs</h3>
<p>Nous allons ensuite faire en sorte de pouvoir ouvrir davantage de descripteurs de fichiers que les 1024 autorisés par défaut pour un utilisateur.</p>
<pre><code>cat &gt; /etc/security/limits.d/tsung.conf &lt;&lt;EOD
* - nofile 65536
root - nofile 65536
EOD</code></pre>
<p>On applique ensuite les changements
killall -HUP 1</p>
<p>Il est également nécessaire de se déconnecter/reconnecter de son shell courant.</p>
<h3>configuration</h3>
<p>cf tsung.xml</p>
<h2>Pour ceux qui ont vraiment le temps</h2>
<p>On peut définit un deuxième groupe d&#39;autoscaling : sans ELB, avec une configuration de lancement permettant de lancer des machines Tsung simulant des utilisateurs de notre webservice.</p>
<p>Les Tsung devraient gagner :)</p>
