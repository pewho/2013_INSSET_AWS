<h1>Atelier AutoScaling EC2</h1>
<p>Nous allons utiliser l&#39;<a href="http://aws.amazon.com/fr/autoscaling/">AutoScaling AWS</a> pour mettre en place un webservice de manipulation d&#39;images qui puisse s&#39;adapter à la charge entrante tout en minimisant les coûts de possession. Pour cela, nous allons partir d&#39;une AMI, automatiser intégralement son lancement, puis l&#39;injecter dans la configuration de notre groupe d&#39;autoscaling afin de pouvoir faire varier le nombre de machines derrière un Elastic Load Balancer.</p>
<p><img src="Architecture.png" alt="Autoscaling"></p>
<p>Pour information, nous allons utiliser une AMI Amazon sur laquelle nous allons installer NodeJS, ImageMagick et <a href="https://github.com/dawanda/node-imageable-server">node-imageable-server</a>, pour fournir un webservice basique (qui tournera en root sur le port 80). Il est également nécessaire d&#39;installer les <a href="http://aws.amazon.com/developertools/351">EC2 API tools</a>, les <a href="http://aws.amazon.com/developertools/2536">ELB tools</a>, les <a href="http://aws.amazon.com/developertools/2534">CloudWatch tools</a> et les <a href="http://aws.amazon.com/developertools/2535">AutoScaling tools</a>.</p>
<h2>Automatisation du boot de l&#39;instance</h2>
<p>Afin d&#39;aller à l&#39;essentiel (cette partie du job peut tout à fait être effectuée par un outil d&#39;orchestration comme Puppet), nous utiliserons les user-data de l&#39;instance pour injecter un script shell exécuté en fin de boot. Celui-ci est en charge :</p>
<ul>
<li>de l&#39;installation de NodeJS, git et ImageMagick,</li>
<li>l&#39;optimisation réseau afin de gérer un grand nombre de courtes connexions TCP simultanées,</li>
<li>l&#39;installation et le lancement de node-imageable-server.</li>
</ul>
<p>L&#39;ensemble du script de lancement à passer en user-data est fourni en pièce-jointe de cette page <a href="user-data-imageable">user-data-imageable</a>. A noter qu&#39;il est primordial de minimiser le temps de boot d&#39;une instance afin que notre groupe d&#39;autoscaling soit suffisamment réactif en cas de pic de charge.
Nous allons maintenant pouvoir déclarer les éléments d&#39;infrastructure : ELB et AutoScaling</p>
<h2>Déclaration de l&#39;ELB</h2>
<p>On déclare un ELB nommé upicardie-asdemo sur la zone us-east-1d, qui écoute sur le port 80 et qui répartit les requêtes sur le port 80 des instances :</p>
<pre><code class="lang-bash">elb-create-lb upicardie-asdemo \
  --availability-zones us-east-1d \
  --listener &quot;lb-port=80,instance-port=80,protocol=http&quot;</code></pre>
<p>On configure ses tests de viabilité d&#39;une instance :</p>
<pre><code class="lang-bash">elb-configure-healthcheck upicardie-asdemo --target &quot;HTTP:80/&quot; --interval 10 --timeout 5 --unhealthy-threshold 2 --healthy-threshold 2</code></pre>
<p>Ces tests sont vitaux afin de s&#39;assurer que l&#39;instance cible ne rentre dans l&#39;ELB que quand  elle est pleinement opérationnelle (à l&#39;issue de son boot via user-data)</p>
<h2>Déclaration des groupes de sécurité</h2>
<p>Les instances d&#39;une groupe d&#39;autoscaling ne dérogent pas aux règles en vigueur sur EC2, elles doivent faire partie d&#39;au moins un groupe de sécurité. Ainsi, nous déclarerons :</p>
<ul>
<li>upicardie-asdemo-common : le groupe commun à toutes les instances. Autorise le ping et le SSH de partout.</li>
<li>upicardie-asdemo-web : le groupe des instances Web. Autorise le HTTP à partir du groupe de sécurité de l&#39;ELB (sg-35b1b441 dans notre cas)</li>
</ul>
<pre><code class="lang-bash">ec2addgrp upicardie-asdemo-common -d &quot;Serveurs upicardie-asdemo&quot;
ec2addgrp upicardie-asdemo-web -d &quot;Serveurs Web upicardie-asdemo&quot;

ec2auth upicardie-asdemo-common -P icmp -t &quot;-1:-1&quot;
ec2auth upicardie-asdemo-common -P tcp -p 22

ec2auth upicardie-asdemo-web -P tcp -p 80 -u amazon-elb -o sg-35b1b441</code></pre>
<h2>Création de la configuration de lancement</h2>
<p>Avant de déclarer le groupe d&#39;autoscaling à proprement parler, nous allons définir tout ce qui est relatif à une instance du groupe, à savoir :</p>
<ul>
<li>son AMI (ami-94cd60fd)</li>
<li>son type m1.small</li>
<li>ses groupes de sécurité (upicardie-asdemo-common et upicardie-asdemo-web)</li>
<li>le fichier user-data qu&#39;on a préparé (user-data-imageable, stocké dans le répertoire courant de la machine à partir de laquelle on tape les commandes d&#39;autoscaling)</li>
<li>la clé pour l&#39;accès SSH (upicardie-us-east1)</li>
</ul>
<pre><code class="lang-bash">as-create-launch-config upicardie-asdemo-lc \
  --image-id ami-94cd60fd \
  --instance-type m1.small \
  --group upicardie-asdemo-common,upicardie-asdemo-web \
  --user-data-file user-data-imageable \
  --key upicardie-us-east1</code></pre>
<h2>Création du groupe d&#39;autoscaling</h2>
<p>Maintenant que nous avons défini la configuration de lancement, nous pouvons déclarer le groupe d&#39;autoscaling avec les paramètres suivants :</p>
<ul>
<li>la configuration de lancement (upicardie-asdemo-lc)</li>
<li>la ou les zone(s) sur lesquelles l&#39;autoscaling prend effet (us-east-1d, en accord avec la déclaration de l&#39;ELB)</li>
<li>le nombre minimal et maximal d&#39;instances (pour assurer à la fois une certaine disponibilité/QoS et maîtriser les coûts de possession)</li>
<li>le nom de l&#39;ELB dans lequel inscrire/désinscrire les instances</li>
<li>le type de test de viabilité (soit celui d&#39;EC2, garantissant la partie hardware, soit celui de l&#39;ELB assurant la disponibilité applicative)</li>
<li>la période de grâce (= la durée pendant laquelle l&#39;instance n&#39;est pas testée après son lancement. Grosso-modo son temps de boot).</li>
</ul>
<pre><code class="lang-bash">as-create-auto-scaling-group upicardie-asdemo-asg \
  --launch-configuration upicardie-asdemo-lc \
  --availability-zones us-east-1d \
  --min-size 0 --max-size 0 \
  --load-balancers upicardie-asdemo \
  --health-check-type EC2 \
  --grace-period 300</code></pre>
<h2>Triggers de mise à l&#39;échelle</h2>
<p>Il est ensuite nécessaire de définir la politiques de mises à l&#39;échelle de l&#39;architecture, à la hausse comme à la baisse. Chaque élément AWS (ELB, volume, instance...) dispose de métriques CloudWatch sur lesquelles nous allons nous appuyer pour lancer ou éteindre des machines. Les instances d&#39;un groupe d&#39;autoscaling disposent notamment d&#39;une surveillance CloudWatch détaillée (pas de 1 minute à la place des 5 minutes par défaut).
Commençons par définir notre politique d&#39;ajout de machines (upicardie-asdemo-scale-up) : Nous ajoutons 50% de machines en plus. Le paramètre --cooldown permet de définir une durée (en seconde) pendant laquelle la politique de mise à l&#39;échelle ne sera plus appelée. C&#39;est utile pour laisser les instances se lancer et pour voir les premiers bénéfices de l&#39;ajout d&#39;instances.</p>
<pre><code class="lang-bash">as-put-scaling-policy upicardie-asdemo-scale-up \
  --auto-scaling-group upicardie-asdemo-asg \
  --adjustment 50 \
  --type PercentChangeInCapacity \
  --cooldown 300</code></pre>
<p>Même chose pour le retrait de machine : on enlève les machines une à une du groupe d&#39;autoscaling. L&#39;idée est ici de croitre beaucoup plus vite qu&#39;on ne décroit pour pouvoir encaisser facilement des pics de charge successifs.</p>
<pre><code class="lang-bash">as-put-scaling-policy upicardie-asdemo-scale-down \
  --auto-scaling-group upicardie-asdemo-asg \
  --adjustment=-1 \
  --type ChangeInCapacity \
  --cooldown 300</code></pre>
<p>L&#39;invocation des commandes ci-dessus renvoie à chaque fois une référence que nous allons pouvoir injecter dans nos déclencheurs... A commencer par la mise à l&#39;échelle à la hausse lorsque :</p>
<ul>
<li>l&#39;utilisation CPU moyenne (--statistic Average --metric-name CPUUtilization)</li>
<li>du groupe d&#39;autoscaling upicardie-asdemo-asg (--namespace &quot;AWS/EC2&quot; --dimensions &quot;AutoScalingGroupName=upicardie-asdemo-asg&quot;)</li>
<li>est supérieure (--comparison-operator GreaterThanThreshold)</li>
<li>à 70% (--threshold 70)</li>
<li>pendant plus de 2 relevés distants de 60 secondes (--period 60 --evaluation-periods 2)</li>
</ul>
<pre><code class="lang-bash">mon-put-metric-alarm upicardie-asdemo-highcpualarm \
  --comparison-operator GreaterThanThreshold \
  --statistic Average --metric-name CPUUtilization \
  --namespace &quot;AWS/EC2&quot; --dimensions &quot;AutoScalingGroupName=upicardie-asdemo-asg&quot; \
  --period 60 --threshold 70 --evaluation-periods 2 \
  --alarm-actions arn:aws:autoscaling:us-east-1:073044293698:scalingPolicy:645473c9-46f4-40a3-8eca-2826d7678548:autoScalingGroupName/upicardie-asdemo-asg:policyName/upicardie-asdemo-scale-up</code></pre>
<p>Pareil avec la mise à l&#39;échelle à la baisse lorsque :</p>
<ul>
<li>l&#39;utilisation CPU moyenne (<code>--statistic Average --metric-name CPUUtilization</code>)</li>
<li>du groupe d&#39;autoscaling upicardie-asdemo-asg (<code>--namespace &quot;AWS/EC2&quot; --dimensions &quot;AutoScalingGroupName=upicardie-asdemo-asg&quot;</code>)</li>
<li>est supérieure (<code>--comparison-operator LessThanThreshold</code>)</li>
<li>à 36% (<code>--threshold 36</code>)</li>
<li>pendant plus de 2 relevés distants de 60 secondes (<code>--period 60 --evaluation-periods 2</code>)</li>
</ul>
<pre><code class="lang-bash">mon-put-metric-alarm upicardie-asdemo-lowcpualarm \
  --comparison-operator LessThanThreshold \
  --statistic Average --metric-name CPUUtilization \
  --namespace &quot;AWS/EC2&quot; --dimensions &quot;AutoScalingGroupName=upicardie-asdemo-asg&quot; \
  --period 60 --threshold 36 --evaluation-periods 2 \
  --alarm-actions arn:aws:autoscaling:us-east-1:073044293698:scalingPolicy:42005b3f-44b3-4aa2-b352-156cb6bdd428:autoScalingGroupName/upicardie-asdemo-asg:policyName/upicardie-asdemo-scale-down</code></pre>
<p>Nous allons ensuite prendre soin de la QoS de notre service en définissant une mise à l&#39;échelle à la hausse lorsque :</p>
<ul>
<li>la latence moyenne (<code>--statistic Average --metric-name Latency</code>)</li>
<li>du load-balancer upicardie-asdemo (<code>--namespace &quot;AWS/ELB&quot; --dimensions &quot;LoadBalancerName=upicardie-asdemo&quot;</code>)</li>
<li>est supérieure (<code>--comparison-operator LessThanThreshold</code>)</li>
<li>à 3 secondes (<code>--threshold 3</code>)</li>
<li>dès le premier relevé (<code>--period 60 --evaluation-periods 1</code>)</li>
</ul>
<pre><code class="lang-bash">mon-put-metric-alarm upicardie-asdemo-highlatencyalarm \
  --comparison-operator GreaterThanThreshold \
  --statistic Average --metric-name Latency \
  --namespace &quot;AWS/ELB&quot; --dimensions &quot;LoadBalancerName=upicardie-asdemo&quot; \
  --period 60 --threshold 3 --evaluation-periods 1 \
  --alarm-actions arn:aws:autoscaling:us-east-1:073044293698:scalingPolicy:645473c9-46f4-40a3-8eca-2826d7678548:autoScalingGroupName/upicardie-asdemo-asg:policyName/upicardie-asdemo-scale-up</code></pre>
<p>Notre autoscaling est dorénavant fonctionnel. Pour lancer le service, il suffit de passer le min/max du nombre d&#39;instances du groupe d&#39;autoscaling de 0/0 à 2/12 par exemple :</p>
<pre><code class="lang-bash">as-update-auto-scaling-group upicardie-asdemo-asg --min-size 2 --max-size 12</code></pre>
<h2>Mise à l&#39;échelle programmée</h2>
<p>Dans certains cas, il est possible de prévoir la charge sur la plate-forme et de programmer, à une certaine heure et une certaine récurrence la mise à l&#39;échelle de l&#39;autoscaling en jouant sur le min/max par exemple. Les deux régles suivantes vont définir un passage à 3 instances minimum à 22h15 UTC chaque jour (syntaxe cron) :</p>
<pre><code class="lang-bash">as-put-scheduled-update-group-action upicardie-asdemo-preemptive-upscale \
  --auto-scaling-group upicardie-asdemo-asg \
  --min-size 4 \
  --max-size 12 \
  --recurrence &quot;15 22 * * *&quot;</code></pre>
<p>suivi d&#39;un retour à 2 instances minimum à 4h00 UTC chaque jour :</p>
<pre><code class="lang-bash">as-put-scheduled-update-group-action upicardie-asdemo-preemptive-downscale \
  --auto-scaling-group upicardie-asdemo-asg \
  --min-size 2 \
  --max-size 12 \
  --recurrence &quot;0 4 * * *&quot;</code></pre>
<h2>Mise à jour de l&#39;autoscaling</h2>
<p>Les commandes d&#39;autoscaling prévoient la mise à jour du groupe d&#39;autoscaling, mais pas de la configuration de lancement de ce même groupe. Qu&#39;importe, nous pouvons contourner cette limitation en passant une configuration de lancement temporaire. Si nous voulons par exemple changer l&#39;AMI de nos instances de ami-94cd60fd vers ami-42421337 :</p>
<pre><code class="lang-bash">as-create-launch-config upicardie-asdemo-lc-tmp \
  --image-id ami-42421337 \
  --instance-type m1.small \
  --group upicardie-asdemo-common,upicardie-asdemo-web \
  --user-data-file user-data-imageable \
  --key upicardie-us-east1

as-update-auto-scaling-group upicardie-asdemo-asg \
  --launch-configuration upicardie-asdemo-lc-tmp

as-delete-launch-config -f --launch-config upicardie-asdemo-lc

as-create-launch-config upicardie-asdemo-lc \
  --image-id ami-42421337 \
  --instance-type m1.small \
  --group upicardie-asdemo-common,upicardie-asdemo-web \
  --user-data-file user-data-imageable \
  --key upicardie-us-east1

as-update-auto-scaling-group upicardie-asdemo-asg \
  --launch-configuration upicardie-asdemo-lc

as-delete-launch-config -f --launch-config upicardie-asdemo-lc-tmp</code></pre>
<p>Note : cette double déclaration de configurations de lancement peut être évitée si on horodate le nom de la configuration plutôt que de le garder fixe.</p>
<h2>Fight!</h2>
<p>En guise de démonstration, nous avons définis deux groupes d&#39;autoscaling :
celui du service web précédemment décrit
un sans ELB, avec une configuration de lancement permettant de lancer des machines Tsung simulant des utilisateurs de notre webservice.</p>
<p>Les Tsung ont gagné :)</p>
