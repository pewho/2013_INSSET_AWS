<!DOCTYPE html>
<html>
<title>Atelier AutoScaling EC2</title>


<xmp theme="simplex" style="display:none;">



Nous allons utiliser l'[AutoScaling AWS](http://aws.amazon.com/fr/autoscaling/) pour mettre en place un webservice de manipulation d'images qui puisse s'adapter à la charge entrante tout en minimisant les coûts de possession. Pour cela, nous allons partir d'une AMI, automatiser intégralement son lancement, puis l'injecter dans la configuration de notre groupe d'autoscaling afin de pouvoir faire varier le nombre de machines derrière un Elastic Load Balancer.

![Autoscaling](img/Architecture.png)


Pour information, nous allons utiliser une AMI Amazon sur laquelle nous allons installer NodeJS, ImageMagick et [node-imageable-server](https://github.com/bobuss/node-imageable-server), pour fournir un webservice basique (qui tournera en root sur le port 80). Il est également nécessaire d'installer [aws-cli](https://github.com/aws/aws-cli).


Automatisation du boot de l'instance
------------------------------------

Afin d'aller à l'essentiel (cette partie du job peut tout à fait être effectuée par un outil d'orchestration comme Puppet), nous utiliserons les user-data de l'instance pour injecter un script shell exécuté en fin de boot. Celui-ci est en charge :

- de l'installation de NodeJS, git et ImageMagick,
- l'optimisation réseau afin de gérer un grand nombre de courtes connexions TCP simultanées,
- l'installation et le lancement de node-imageable-server.

L'ensemble du script de lancement à passer en user-data est fourni en pièce-jointe de cette page [user-data-imageable](files/user-data-imageable). A noter qu'il est primordial de minimiser le temps de boot d'une instance afin que notre groupe d'autoscaling soit suffisamment réactif en cas de pic de charge.
Nous allons maintenant pouvoir déclarer les éléments d'infrastructure : ELB et AutoScaling


Déclaration de l'ELB
--------------------

On déclare un ELB nommé upicardie-asdemo sur la zone us-east-1d, qui écoute sur le port 80 et qui répartit les requêtes sur le port 80 des instances :

```
aws elb create-load-balancer \
  --load-balancer-name upicardie-asdemo \
  --availability-zones us-east-1d \
  --listeners "LoadBalancerPort=80,InstancePort=80,Protocol=http"
{
    "DNSName": "upicardie-asdemo-764036086.us-east-1.elb.amazonaws.com"
}
```

On configure ses tests de viabilité d'une instance :

```bash
aws elb configure-health-check \
  --load-balancer-name upicardie-asdemo \
  --health-check Target="HTTP:80/",Interval=10,Timeout=5,UnhealthyThreshold=2,HealthyThreshold=2
{
    "HealthCheck": {
        "HealthyThreshold": 2,
        "Interval": 10,
        "Target": "HTTP:80/",
        "Timeout": 5,
        "UnhealthyThreshold": 2
    }
}
```

Ces tests sont vitaux afin de s'assurer que l'instance cible ne rentre dans l'ELB que quand  elle est pleinement opérationnelle (à l'issue de son boot via user-data)


Déclaration des groupes de sécurité
-----------------------------------

Les instances d'une groupe d'autoscaling ne dérogent pas aux règles en vigueur sur EC2, elles doivent faire partie d'au moins un groupe de sécurité. Ainsi, nous déclarerons :

- upicardie-asdemo-common : le groupe commun à toutes les instances. Autorise le ping et le SSH de partout.
- upicardie-asdemo-web : le groupe des instances Web. Autorise le HTTP à partir du groupe de sécurité de l'ELB (sg-6563ed0e dans notre cas)

```bash
aws ec2 create-security-group \
  --group-name upicardie-asdemo-common \
  --description "Serveurs upicardie-asdemo"
{
    "return": "true",
    "GroupId": "sg-8962ece2"
}
```

```bash
aws ec2 create-security-group \
    --group-name upicardie-asdemo-web \
    --description "Serveurs Web upicardie-asdemo"
{
    "return": "true",
    "GroupId": "sg-6563ed0e"
}
```

```bash
aws ec2 authorize-security-group-ingress \
  --group-name upicardie-asdemo-common \
  --protocol icmp
  --port -1
{
    "return": "true"
}
```

```bash
aws ec2 authorize-security-group-ingress \
  --group-name upicardie-asdemo-common \
  --protocol tcp \
  --port 22
{
    "return": "true"
}
```

```bash
aws ec2 authorize-security-group-ingress \
  --group-name upicardie-asdemo-web \
  --protocol tcp \
  --port 80 \
  --source-group sg-6563ed0e
{
    "IpPermissionsEgress": [],
    "Description": "Serveurs Web upicardie-asdemo",
    "IpPermissions": [
        {
            "ToPort": 80,
            "IpProtocol": "tcp",
            "IpRanges": [],
            "UserIdGroupPairs": [
                {
                    "GroupName": "upicardie-asdemo-web",
                    "UserId": "511122800347",
                    "GroupId": "sg-6563ed0e"
                }
            ],
            "FromPort": 80
        }
    ],
    "GroupName": "upicardie-asdemo-web",
    "OwnerId": "511122800347",
    "GroupId": "sg-6563ed0e"
}

```


Création de la configuration de lancement
-----------------------------------------

Avant de déclarer le groupe d'autoscaling à proprement parler, nous allons définir tout ce qui est relatif à une instance du groupe, à savoir :

- son AMI (ami-94cd60fd)
- son type t1.micro
- ses groupes de sécurité (upicardie-asdemo-common et upicardie-asdemo-web)
- le fichier user-data qu'on a préparé (user-data-imageable, stocké dans le répertoire courant de la machine à partir de laquelle on tape les commandes d'autoscaling)
- la clé pour l'accès SSH (MyKeyPair générée normalement plus tôt)

```bash
aws autoscaling create-launch-configuration \
  --launch-configuration-name upicardie-asdemo-lc \
  --image-id ami-94cd60fd \
  --instance-type t1.micro \
  --security-groups '["upicardie-asdemo-common","upicardie-asdemo-web"]' \
  --user-data user-data-imageable \
  --key-name MyKeyPair
{}
```

```bash
aws autoscaling describe-launch-configurations
{
    "LaunchConfigurations": [
        {
            "UserData": "dXNlci1kYXRhLWltYWdlYWJsZQ==",
            "EbsOptimized": false,
            "LaunchConfigurationARN": "arn:aws:autoscaling:us-east-1:511122800347:launchConfiguration:4c9d7ee0-47cd-407d-bc5d-bef4f7fe8195:launchConfigurationName/upicardie-asdemo-lc",
            "InstanceMonitoring": {
                "Enabled": true
            },
            "ImageId": "ami-94cd60fd",
            "CreatedTime": "2013-08-28T22:13:31.740Z",
            "BlockDeviceMappings": [],
            "KeyName": "MyKeyPair",
            "SecurityGroups": [
                "upicardie-asdemo-common",
                "upicardie-asdemo-web"
            ],
            "LaunchConfigurationName": "upicardie-asdemo-lc",
            "KernelId": null,
            "RamdiskId": null,
            "InstanceType": "t1.micro"
        }
    ]
}

```

Création du groupe d'autoscaling
--------------------------------

Maintenant que nous avons défini la configuration de lancement, nous pouvons déclarer le groupe d'autoscaling avec les paramètres suivants :

- la configuration de lancement (upicardie-asdemo-lc)
- la ou les zone(s) sur lesquelles l'autoscaling prend effet (us-east-1d, en accord avec la déclaration de l'ELB)
- le nombre minimal et maximal d'instances (pour assurer à la fois une certaine disponibilité/QoS et maîtriser les coûts de possession)
- le nom de l'ELB dans lequel inscrire/désinscrire les instances
- le type de test de viabilité (soit celui d'EC2, garantissant la partie hardware, soit celui de l'ELB assurant la disponibilité applicative)
- la période de grâce (= la durée pendant laquelle l'instance n'est pas testée après son lancement. Grosso-modo son temps de boot).

```bash
aws autoscaling create-auto-scaling-group \
  --auto-scaling-group-name upicardie-asdemo-asg \
  --launch-configuration-name upicardie-asdemo-lc \
  --availability-zones us-east-1d \
  --min-size 0 --max-size 0 \
  --load-balancer-names upicardie-asdemo \
  --health-check-type EC2 \
  --health-check-grace-period 300
```


```bash
aws autoscaling describe-auto-scaling-groups
{
    "AutoScalingGroups": [
        {
            "AutoScalingGroupARN": "arn:aws:autoscaling:us-east-1:511122800347:autoScalingGroup:eca4e01a-06f0-4373-8ab2-7210c006c450:autoScalingGroupName/upicardie-asdemo-asg",
            "HealthCheckGracePeriod": 300,
            "SuspendedProcesses": [],
            "DesiredCapacity": 0,
            "Tags": [],
            "EnabledMetrics": [],
            "LoadBalancerNames": [
                "upicardie-asdemo"
            ],
            "AutoScalingGroupName": "upicardie-asdemo-asg",
            "DefaultCooldown": 300,
            "MinSize": 0,
            "Instances": [],
            "MaxSize": 0,
            "VPCZoneIdentifier": null,
            "TerminationPolicies": [
                "Default"
            ],
            "LaunchConfigurationName": "upicardie-asdemo-lc",
            "CreatedTime": "2013-08-28T22:19:51.106Z",
            "AvailabilityZones": [
                "us-east-1d"
            ],
            "HealthCheckType": "EC2"
        }
    ]
}

```

Triggers de mise à l'échelle
----------------------------

Il est ensuite nécessaire de définir la politiques de mises à l'échelle de l'architecture, à la hausse comme à la baisse. Chaque élément AWS (ELB, volume, instance...) dispose de métriques CloudWatch sur lesquelles nous allons nous appuyer pour lancer ou éteindre des machines. Les instances d'un groupe d'autoscaling disposent notamment d'une surveillance CloudWatch détaillée (pas de 1 minute à la place des 5 minutes par défaut).
Commençons par définir notre politique d'ajout de machines (upicardie-asdemo-scale-up) : Nous ajoutons 50% de machines en plus. Le paramètre `--cooldown` permet de définir une durée (en seconde) pendant laquelle la politique de mise à l'échelle ne sera plus appelée. C'est utile pour laisser les instances se lancer et pour voir les premiers bénéfices de l'ajout d'instances.

```bash
aws autoscaling put-scaling-policy \
  --policy-name upicardie-asdemo-scale-up \
  --auto-scaling-group-name upicardie-asdemo-asg \
  --scaling-adjustment 50 \
  --adjustment-type PercentChangeInCapacity \
  --cooldown 300
{
    "PolicyARN": "arn:aws:autoscaling:us-east-1:511122800347:scalingPolicy:37583020-faf5-4990-a2ec-0aa0ecad9cae:autoScalingGroupName/upicardie-asdemo-asg:policyName/upicardie-asdemo-scale-up"
}
```

Même chose pour le retrait de machine : on enlève les machines une à une du groupe d'autoscaling. L'idée est ici de croitre beaucoup plus vite qu'on ne décroit pour pouvoir encaisser facilement des pics de charge successifs.

```bash
aws autoscaling put-scaling-policy \
  --policy-name upicardie-asdemo-scale-down \
  --auto-scaling-group-name upicardie-asdemo-asg \
  --scaling-adjustment -1 \
  --adjustment-type ChangeInCapacity \
  --cooldown 300
{
    "PolicyARN": "arn:aws:autoscaling:us-east-1:511122800347:scalingPolicy:924d37fe-90f1-466c-90e8-196f9e28b36a:autoScalingGroupName/upicardie-asdemo-asg:policyName/upicardie-asdemo-scale-down"
}
```

L'invocation des commandes ci-dessus renvoie à chaque fois une référence que nous allons pouvoir injecter dans nos déclencheurs... A commencer par la mise à l'échelle à la hausse lorsque :

- l'utilisation CPU moyenne (`--statistic Average --metric-name CPUUtilization`)
- du groupe d'autoscaling upicardie-asdemo-asg (`--namespace "AWS/EC2" --dimensions "Name=AutoScalingGroupName,Value=upicardie-asdemo-asg"`)
- est supérieure (`--comparison-operator GreaterThanThreshold`)
- à 70% (`--threshold 70`)
- pendant plus de 2 relevés distants de 60 secondes (`--period 60 --evaluation-periods 2)

```bash
aws cloudwatch put-metric-alarm \
  --alarm-name upicardie-asdemo-highcpualarm \
  --comparison-operator GreaterThanThreshold \
  --statistic Average \
  --metric-name CPUUtilization \
  --namespace "AWS/EC2" \
  --dimensions "Name=AutoScalingGroupName,Value=upicardie-asdemo-asg" \
  --period 60 \
  --threshold 70 \
  --evaluation-periods 2 \
  --alarm-actions arn:aws:autoscaling:us-east-1:511122800347:scalingPolicy:37583020-faf5-4990-a2ec-0aa0ecad9cae:autoScalingGroupName/upicardie-asdemo-asg:policyName/upicardie-asdemo-scale-up
{}

```

Pareil avec la mise à l'échelle à la baisse lorsque :

- l'utilisation CPU moyenne (`--statistic Average --metric-name CPUUtilization`)
- du groupe d'autoscaling upicardie-asdemo-asg (`--namespace "AWS/EC2" --dimensions "Name=AutoScalingGroupName,Value=upicardie-asdemo-asg"`)
- est supérieure (`--comparison-operator LessThanThreshold`)
- à 36% (`--threshold 36`)
- pendant plus de 2 relevés distants de 60 secondes (`--period 60 --evaluation-periods 2`)

```bash
aws cloudwatch put-metric-alarm \
  --alarm-name upicardie-asdemo-lowcpualarm \
  --comparison-operator LessThanThreshold \
  --statistic Average \
  --metric-name CPUUtilization \
  --namespace "AWS/EC2" \
  --dimensions "Name=AutoScalingGroupName,Value=upicardie-asdemo-asg" \
  --period 60 \
  --threshold 36 \
  --evaluation-periods 2 \
  --alarm-actions arn:aws:autoscaling:us-east-1:511122800347:scalingPolicy:924d37fe-90f1-466c-90e8-196f9e28b36a:autoScalingGroupName/upicardie-asdemo-asg:policyName/upicardie-asdemo-scale-down
{}

```

Nous allons ensuite prendre soin de la QoS de notre service en définissant une mise à l'échelle à la hausse lorsque :

- la latence moyenne (`--statistic Average --metric-name Latency`)
- du load-balancer upicardie-asdemo (`--namespace "AWS/ELB" --dimensions "Name=LoadBalancerName,Value=upicardie-asdemo"`)
- est supérieure (`--comparison-operator LessThanThreshold`)
- à 3 secondes (`--threshold 3`)
- dès le premier relevé (`--period 60 --evaluation-periods 1`)

```bash
aws cloudwatch put-metric-alarm \
  --alarm-name upicardie-asdemo-highlatencyalarm \
  --comparison-operator GreaterThanThreshold \
  --statistic Average \
  --metric-name Latency \
  --namespace "AWS/ELB" \
  --dimensions "Name=LoadBalancerName,Value=upicardie-asdemo" \
  --period 60 \
  --threshold 3 \
  --evaluation-periods 1 \
  --alarm-actions arn:aws:autoscaling:us-east-1:511122800347:scalingPolicy:37583020-faf5-4990-a2ec-0aa0ecad9cae:autoScalingGroupName/upicardie-asdemo-asg:policyName/upicardie-asdemo-scale-up
{}

```

Notre autoscaling est dorénavant fonctionnel. Pour lancer le service, il suffit de passer le min/max du nombre d'instances du groupe d'autoscaling de 0/0 à 2/12 par exemple :

```bash
aws autoscaling update-auto-scaling-group \
  --auto-scaling-group-name upicardie-asdemo-asg \
  --min-size 2 \
  --max-size 12
{}
```

Mise à l'échelle programmée
---------------------------

Dans certains cas, il est possible de prévoir la charge sur la plate-forme et de programmer, à une certaine heure et une certaine récurrence la mise à l'échelle de l'autoscaling en jouant sur le min/max par exemple. Les deux régles suivantes vont définir un passage à 3 instances minimum à 22h15 UTC chaque jour (syntaxe cron) :

```bash
aws aws autoscaling put-scheduled-update-group-action \
  --auto-scaling-group-name upicardie-asdemo-asg \
  --scheduled-action-name upicardie-asdemo-preemptive-upscale \
  --min-size 4 \
  --max-size 12 \
  --recurrence "15 22 * * *"
{}
```

suivi d'un retour à 2 instances minimum à 4h00 UTC chaque jour :

```bash
aws aws autoscaling put-scheduled-update-group-action \
  --auto-scaling-group-name upicardie-asdemo-asg \
  --scheduled-action-name upicardie-asdemo-preemptive-downscale \
  --min-size 2 \
  --max-size 12 \
  --recurrence "0 4 * * *"
{}
```

Mise à jour de l'autoscaling
----------------------------

Les commandes d'autoscaling prévoient la mise à jour du groupe d'autoscaling, mais pas de la configuration de lancement de ce même groupe. Qu'importe, nous pouvons contourner cette limitation en passant une configuration de lancement temporaire. Si nous voulons par exemple changer l'AMI de nos instances de ami-94cd60fd vers ami-7daee114 :

```bash
as-create-launch-config upicardie-asdemo-lc \
  --image-id ami-7daee114 \
  --instance-type t1.micro \
  --group upicardie-asdemo-common,upicardie-asdemo-web \
  --user-data-file user-data-imageable \
  --key MyKeyPair

as-update-auto-scaling-group upicardie-asdemo-asg \
  --launch-configuration upicardie-asdemo-lc-tmp

as-delete-launch-config -f --launch-config upicardie-asdemo-lc

as-create-launch-config upicardie-asdemo-lc \
  --image-id ami-7daee114 \
  --instance-type t1.micro \
  --group upicardie-asdemo-common,upicardie-asdemo-web \
  --user-data-file user-data-imageable \
  --key MyKeyPair

as-update-auto-scaling-group upicardie-asdemo-asg \
  --launch-configuration upicardie-asdemo-lc

as-delete-launch-config -f --launch-config upicardie-asdemo-lc
```

Note : cette double déclaration de configurations de lancement peut être évitée si on horodate le nom de la configuration plutôt que de le garder fixe.


Tester
------

Siege permet de simuler de la charge sur service web, en maintenant ouvert des dizaines voir centaines de connexions pendant une temps défini.

```
sudo apt-get install siege
```

Il suffit de donner à siege le nombre de connexions concurrentes (`-c`), et le temps du test (`-t`).

```
siege -c25 -t10M  upicardie-asdemo-764036086.us-east-1.elb.amazonaws.com
```

Une chose à noter est que le monitoring basique de CloudWatch est rafraichi toutes les 5 minutes. Nos politiques d'auto-scaling doivent se réaliser pendant 3 minutes consécutives. Donc, pour que siege puisse déclencher l'auto-scaling, il faut le laisser tourner 6 à 10 minutes. Enfin, il faut rafraichir l'onglet CloudWatch dans la console AWS afin de vérifier que des serveurs se lancent.

![AutoScaling](img/AutoScaleAnimation.gif)


Crédits
-------

- Basé sur un atelier Autoscaling de [Guillaume Plessis](https://twitter.com/@gui).
- Gif animé autoscaling : http://www.cardinalpath.com/autoscaling-your-website-with-amazon-web-services-part-2/

</xmp>
<a class="home-link" href="index.html">...</a>
<style>
a.home-link {
    position: fixed;
    top : 4px;
    left: 4px;
    width : 32px;
    height: 32px;
    z-index : 1;
    font-size: 40px;
}
</style>
<script src="strapdown/strapdown.js"></script>
<!-- GA -->
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-32527212-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
<!-- End GA -->

</html>
